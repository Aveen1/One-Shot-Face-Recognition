{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code till now\n",
    "#Loading used Libraries\n",
    "import FaceToolKit as ftk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import cv2\n",
    "#For Image Capturing after 5 seconds\n",
    "import cv2\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#Specify the threshold and size of the network input\n",
    "verification_threshhold = 0.8\n",
    "image_size = 160\n",
    "\n",
    "#Creating an object from a written class\n",
    "v = ftk.Verification()\n",
    "\n",
    "#Load a trained model and specify the input and output network tensors\n",
    "# Pre-load model for Verification\n",
    "v.load_model(\"./models/20180204-160909/\")\n",
    "v.initial_input_output_tensors()\n",
    "\n",
    "\n",
    "#img capturing after 5 sec\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(3, 640)\n",
    "capture.set(4, 480)\n",
    "img_counter = 0\n",
    "frame_set = []\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if time.time() - start_time >= 5: #<---- Check if 5 sec passed\n",
    "        img_name = \"C:/Users/Aveen Faheem/Desktop/Anaconda_work/deep-face-recognition-master/deep-face-recognition-master/img/frame{}.jpg\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_counter))\n",
    "        start_time = time.time()\n",
    "        img1 = plt.imread(img_name) #set path to first image coming from webcam\n",
    "        plt.imshow(img1)\n",
    "        plt.show()\n",
    "        \n",
    "        img2 = plt.imread(\"./images/19.jpg\")#set path to second image coming from folder\n",
    "        plt.imshow(img2)\n",
    "        plt.show()\n",
    "        \n",
    "        #Resizing first image\n",
    "        import cv2\n",
    "        img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "        print('Original Dimensions : ',img.shape)\n",
    "        width = 160\n",
    "        height = 160\n",
    "        dim = (width, height) \n",
    "        # resize image\n",
    "        img1 = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        print('Resized Dimensions : ',img1.shape)\n",
    "        \n",
    "        \n",
    "        #Resizing second image\n",
    "        img = cv2.imread(\"./images/19.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "        print('Original Dimensions : ',img.shape)\n",
    "        width = 160\n",
    "        height = 160\n",
    "        dim = (width, height) \n",
    "        # resize image\n",
    "        img2 = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        print('Resized Dimensions : ',img2.shape)\n",
    "        \n",
    "        \n",
    "        #embeddings for both images\n",
    "        emb1 = v.img_to_encoding(img1, image_size)\n",
    "        emb2 = v.img_to_encoding(img2, image_size)\n",
    "        \n",
    "        #Formula for embeddings\n",
    "        def distance(emb1, emb2):\n",
    "            diff = np.subtract(emb1, emb2)\n",
    "            return np.sum(np.square(diff))\n",
    "        #distance\n",
    "        dist = distance(emb1, emb2)\n",
    "        is_same = dist < verification_threshhold\n",
    "        print (\"Distance between img1 and img2 = \", dist, \" is same =\", is_same)\n",
    "        \n",
    "        #Script that deletes each picture one by one\n",
    "        import glob,os\n",
    "        directory=\"C:/Users/Aveen Faheem/Desktop/Anaconda_work/deep-face-recognition-master/deep-face-recognition-master/img\"\n",
    "        for i in glob.glob(os.path.join(directory,\"*.jpg\")):\n",
    "            try:\n",
    "                os.chmod(i,0o777)\n",
    "                os.remove(i)\n",
    "            except OSError:\n",
    "                pass\n",
    "    img_counter += 1\n",
    "    #img counter for next image\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
